"""
Model Card Generator - Analyse de Donn√©es Hospitali√®res
========================================================
Ce script entra√Æne les mod√®les de machine learning et g√©n√®re automatiquement
les Model Cards avec visualisations des performances.

Auteur: Paul-Henri DOURNEAU & Dorian MARTY
Date: 30/01/2026
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.metrics import (classification_report, mean_squared_error, r2_score, 
                             confusion_matrix, roc_curve, auc, precision_recall_curve,
                             mean_absolute_error)
import joblib
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# CONFIGURATION
# =============================================================================

INPUT_FILE = r'c:\Users\Ph\Documents\.EPSI\Documentations\hospital_deterioration_hourly_panel.csv'
OUTPUT_DIR = r'c:\Users\Ph\Documents\.EPSI\Documentations'

if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['figure.dpi'] = 150

print(f"[INFO] Chargement des donn√©es depuis {INPUT_FILE}...")
df = pd.read_csv(INPUT_FILE)
print(f"[INFO] Donn√©es charg√©es: {df.shape[0]} lignes, {df.shape[1]} colonnes")

# =============================================================================
# PR√âPARATION DES DONN√âES
# =============================================================================

print("[INFO] Nettoyage et normalisation des donn√©es...")
df_clean = df.copy()

# 1. Gestion des valeurs manquantes
# Strat√©gie: Moyenne pour num√©riques, mode pour cat√©gorielles
for col in df_clean.columns:
    if df_clean[col].dtype in ['float64', 'int64']:
        df_clean[col] = df_clean[col].fillna(df_clean[col].mean())
    else:
        df_clean[col] = df_clean[col].fillna(df_clean[col].mode()[0])

# 2. Encodage des variables cat√©gorielles
categorical_cols = df_clean.select_dtypes(exclude=[np.number]).columns
encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    df_clean[col] = le.fit_transform(df_clean[col].astype(str))
    encoders[col] = le

# 3. D√©finition des features (excluant les targets et identifiants)
excluded_cols = ['deterioration_event', 'los_hours', 'patient_id', 
                 'deterioration_hour', 'deterioration_next_12h', 
                 'deterioration_within_12h_from_admission']
feature_cols = [c for c in df_clean.columns if c not in excluded_cols]

# 4. Normalisation
scaler = StandardScaler()
df_clean[feature_cols] = scaler.fit_transform(df_clean[feature_cols])

# Sauvegarde des donn√©es nettoy√©es
cleaned_data_path = os.path.join(OUTPUT_DIR, 'hospital_data_cleaned_normalized.csv')
df_clean.to_csv(cleaned_data_path, index=False)
print(f"[OK] Donn√©es nettoy√©es sauvegard√©es: {cleaned_data_path}")

# Log des transformations
transformation_log = f"""# Log des Transformations de Donn√©es

**Date**: {datetime.now().strftime('%d/%m/%Y √† %H:%M')}

## √âtapes de Pr√©traitement

### 1. Gestion des Valeurs Manquantes
- **Strat√©gie num√©riques**: Imputation par la moyenne
- **Strat√©gie cat√©gorielles**: Imputation par le mode (valeur la plus fr√©quente)
- **Justification**: Conserver le maximum de donn√©es sans introduire de biais significatif

### 2. Encodage des Variables Cat√©gorielles
Variables encod√©es avec LabelEncoder:
{chr(10).join([f'- `{col}`: {len(encoders[col].classes_)} classes' for col in encoders])}

### 3. Normalisation (StandardScaler)
- **M√©thode**: Centrage (moyenne=0) et r√©duction (√©cart-type=1)
- **Variables normalis√©es**: {len(feature_cols)} features
- **Justification**: N√©cessaire pour la r√©gression logistique (sensible √† l'√©chelle)

### 4. Variables Exclues de l'Entra√Ænement
{chr(10).join([f'- `{col}`' for col in excluded_cols])}

## Fichier de Sortie
- **Chemin**: `{cleaned_data_path}`
- **Taille**: {df_clean.shape[0]} lignes √ó {df_clean.shape[1]} colonnes
"""

log_path = os.path.join(OUTPUT_DIR, 'transformation_log.md')
with open(log_path, 'w', encoding='utf-8') as f:
    f.write(transformation_log)
print(f"[OK] Log de transformation sauvegard√©: {log_path}")

# =============================================================================
# MOD√àLE 1 : CLASSIFICATION (D√©t√©rioration)
# =============================================================================

print("\n" + "="*60)
print("MOD√àLE 1 : CLASSIFICATION - Pr√©diction de D√©t√©rioration")
print("="*60)

X_cls = df_clean[feature_cols]
y_cls = df_clean['deterioration_event']

X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(
    X_cls, y_cls, test_size=0.2, random_state=42, stratify=y_cls
)

print(f"[INFO] Entra√Ænement: {len(X_train_cls)} samples")
print(f"[INFO] Test: {len(X_test_cls)} samples")
print(f"[INFO] R√©partition classes train: {dict(y_train_cls.value_counts())}")

# Entra√Ænement
clf = LogisticRegression(max_iter=1000, C=1.0, class_weight='balanced', random_state=42)
clf.fit(X_train_cls, y_train_cls)

# Pr√©dictions
y_pred_cls = clf.predict(X_test_cls)
y_proba_cls = clf.predict_proba(X_test_cls)[:, 1]

# M√©triques
cls_report = classification_report(y_test_cls, y_pred_cls)
cls_report_dict = classification_report(y_test_cls, y_pred_cls, output_dict=True)

print("\n[R√âSULTATS] Classification Report:")
print(cls_report)

# Sauvegarder le mod√®le
model_cls_path = os.path.join(OUTPUT_DIR, 'model_classification.joblib')
joblib.dump(clf, model_cls_path)
print(f"[OK] Mod√®le sauvegard√©: {model_cls_path}")

# --- VISUALISATIONS CLASSIFICATION ---

# 1. Matrice de Confusion
print("[INFO] G√©n√©ration de la matrice de confusion...")
cm = confusion_matrix(y_test_cls, y_pred_cls)

fig, ax = plt.subplots(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
            xticklabels=['Stable (0)', 'D√©t√©rioration (1)'],
            yticklabels=['Stable (0)', 'D√©t√©rioration (1)'],
            annot_kws={'size': 14})
ax.set_xlabel('Pr√©diction', fontsize=12)
ax.set_ylabel('R√©alit√©', fontsize=12)
ax.set_title('Matrice de Confusion - Mod√®le de Classification', fontsize=14, fontweight='bold')

# Ajouter les taux
tn, fp, fn, tp = cm.ravel()
text = f"TN={tn:,} | FP={fp:,}\nFN={fn:,} | TP={tp:,}"
ax.text(1.5, -0.15, f"Pr√©cision D√©t√©rioration: {tp/(tp+fp):.1%}  |  Rappel D√©t√©rioration: {tp/(tp+fn):.1%}", 
        ha='center', fontsize=10, transform=ax.transAxes)

plt.tight_layout()
cm_path = os.path.join(OUTPUT_DIR, 'confusion_matrix.png')
plt.savefig(cm_path, bbox_inches='tight', facecolor='white')
plt.close()
print(f"[OK] Matrice de confusion sauvegard√©e: {cm_path}")

# 2. Courbe ROC
print("[INFO] G√©n√©ration de la courbe ROC...")
fpr, tpr, thresholds = roc_curve(y_test_cls, y_proba_cls)
roc_auc = auc(fpr, tpr)

fig, ax = plt.subplots(figsize=(8, 6))
ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')
ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')
ax.fill_between(fpr, tpr, alpha=0.3, color='darkorange')
ax.set_xlim([0.0, 1.0])
ax.set_ylim([0.0, 1.05])
ax.set_xlabel('Taux de Faux Positifs (1 - Sp√©cificit√©)', fontsize=11)
ax.set_ylabel('Taux de Vrais Positifs (Sensibilit√©)', fontsize=11)
ax.set_title('Courbe ROC - Pr√©diction de D√©t√©rioration', fontsize=14, fontweight='bold')
ax.legend(loc='lower right', fontsize=10)
ax.grid(True, alpha=0.3)

plt.tight_layout()
roc_path = os.path.join(OUTPUT_DIR, 'roc_curve.png')
plt.savefig(roc_path, bbox_inches='tight', facecolor='white')
plt.close()
print(f"[OK] Courbe ROC sauvegard√©e: {roc_path}")

# 3. Feature Importance
print("[INFO] G√©n√©ration du graphique Feature Importance...")
feature_importance = pd.DataFrame({
    'feature': feature_cols,
    'importance': np.abs(clf.coef_[0])
}).sort_values('importance', ascending=True)

# Top 15 features
top_features = feature_importance.tail(15)

fig, ax = plt.subplots(figsize=(10, 8))
colors = plt.cm.RdYlBu_r(np.linspace(0.2, 0.8, len(top_features)))
bars = ax.barh(top_features['feature'], top_features['importance'], color=colors)
ax.set_xlabel('Importance (|Coefficient|)', fontsize=11)
ax.set_title('Top 15 Variables les Plus Importantes\n(R√©gression Logistique)', fontsize=14, fontweight='bold')

# Ajouter les valeurs
for bar, val in zip(bars, top_features['importance']):
    ax.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, 
            f'{val:.3f}', va='center', fontsize=9)

plt.tight_layout()
fi_path = os.path.join(OUTPUT_DIR, 'feature_importance.png')
plt.savefig(fi_path, bbox_inches='tight', facecolor='white')
plt.close()
print(f"[OK] Feature importance sauvegard√©e: {fi_path}")

# =============================================================================
# MOD√àLE 2 : R√âGRESSION (Dur√©e de S√©jour)
# =============================================================================

print("\n" + "="*60)
print("MOD√àLE 2 : R√âGRESSION - Estimation Dur√©e de S√©jour")
print("="*60)

X_reg = df_clean[feature_cols]
y_reg = df_clean['los_hours']

X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(
    X_reg, y_reg, test_size=0.2, random_state=42
)

print(f"[INFO] Entra√Ænement: {len(X_train_reg)} samples")
print(f"[INFO] Test: {len(X_test_reg)} samples")

# Entra√Ænement
reg = LinearRegression()
reg.fit(X_train_reg, y_train_reg)

# Pr√©dictions
y_pred_reg = reg.predict(X_test_reg)

# M√©triques
mse = mean_squared_error(y_test_reg, y_pred_reg)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test_reg, y_pred_reg)
r2 = r2_score(y_test_reg, y_pred_reg)

print(f"\n[R√âSULTATS] R√©gression:")
print(f"  - RMSE: {rmse:.2f} heures")
print(f"  - MAE: {mae:.2f} heures")
print(f"  - R¬≤: {r2:.4f}")

# Sauvegarder le mod√®le
model_reg_path = os.path.join(OUTPUT_DIR, 'model_regression.joblib')
joblib.dump(reg, model_reg_path)
print(f"[OK] Mod√®le sauvegard√©: {model_reg_path}")

# --- VISUALISATIONS R√âGRESSION ---

# 1. Pr√©dictions vs R√©alit√©
print("[INFO] G√©n√©ration du graphique Pr√©dictions vs R√©alit√©...")
fig, ax = plt.subplots(figsize=(8, 8))

# √âchantillonner pour lisibilit√©
sample_size = min(5000, len(y_test_reg))
indices = np.random.choice(len(y_test_reg), sample_size, replace=False)
y_test_sample = np.array(y_test_reg)[indices]
y_pred_sample = y_pred_reg[indices]

ax.scatter(y_test_sample, y_pred_sample, alpha=0.3, c='steelblue', s=10)
ax.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 
        'r--', lw=2, label='Pr√©diction Parfaite')
ax.set_xlabel('Dur√©e R√©elle (heures)', fontsize=11)
ax.set_ylabel('Dur√©e Pr√©dite (heures)', fontsize=11)
ax.set_title('Pr√©dictions vs Valeurs R√©elles\n(Dur√©e de S√©jour)', fontsize=14, fontweight='bold')
ax.legend()

# Ajouter m√©triques
textstr = f'R¬≤ = {r2:.3f}\nRMSE = {rmse:.1f}h\nMAE = {mae:.1f}h'
props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)
ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=10,
        verticalalignment='top', bbox=props)

plt.tight_layout()
pred_vs_real_path = os.path.join(OUTPUT_DIR, 'predictions_vs_reality.png')
plt.savefig(pred_vs_real_path, bbox_inches='tight', facecolor='white')
plt.close()
print(f"[OK] Graphique Pr√©dictions vs R√©alit√© sauvegard√©: {pred_vs_real_path}")

# 2. Distribution des R√©sidus
print("[INFO] G√©n√©ration du graphique des r√©sidus...")
residuals = y_test_reg - y_pred_reg

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Histogramme des r√©sidus
ax1 = axes[0]
sns.histplot(residuals, kde=True, ax=ax1, color='purple', alpha=0.7)
ax1.axvline(0, color='red', linestyle='--', linewidth=2, label='R√©sidu nul')
ax1.axvline(residuals.mean(), color='green', linestyle='-.', linewidth=2, 
            label=f'Moyenne: {residuals.mean():.2f}')
ax1.set_xlabel('R√©sidu (heures)', fontsize=11)
ax1.set_ylabel('Fr√©quence', fontsize=11)
ax1.set_title('Distribution des R√©sidus', fontsize=12, fontweight='bold')
ax1.legend()

# R√©sidus vs Pr√©dictions
ax2 = axes[1]
ax2.scatter(y_pred_reg, residuals, alpha=0.3, c='steelblue', s=10)
ax2.axhline(0, color='red', linestyle='--', linewidth=2)
ax2.axhline(residuals.std()*2, color='orange', linestyle=':', linewidth=1, label='¬±2œÉ')
ax2.axhline(-residuals.std()*2, color='orange', linestyle=':', linewidth=1)
ax2.set_xlabel('Valeur Pr√©dite (heures)', fontsize=11)
ax2.set_ylabel('R√©sidu (heures)', fontsize=11)
ax2.set_title('R√©sidus vs Pr√©dictions', fontsize=12, fontweight='bold')
ax2.legend()

plt.tight_layout()
residuals_path = os.path.join(OUTPUT_DIR, 'residuals_analysis.png')
plt.savefig(residuals_path, bbox_inches='tight', facecolor='white')
plt.close()
print(f"[OK] Analyse des r√©sidus sauvegard√©e: {residuals_path}")

# 3. Coefficients de R√©gression
print("[INFO] G√©n√©ration des coefficients de r√©gression...")
reg_coef = pd.DataFrame({
    'feature': feature_cols,
    'coefficient': reg.coef_
}).sort_values('coefficient', key=abs, ascending=True)

top_reg_coef = reg_coef.tail(15)

fig, ax = plt.subplots(figsize=(10, 8))
colors = ['green' if c > 0 else 'red' for c in top_reg_coef['coefficient']]
bars = ax.barh(top_reg_coef['feature'], top_reg_coef['coefficient'], color=colors, alpha=0.7)
ax.axvline(0, color='black', linewidth=0.8)
ax.set_xlabel('Coefficient', fontsize=11)
ax.set_title('Top 15 Coefficients de R√©gression\n(Vert = ‚Üë dur√©e, Rouge = ‚Üì dur√©e)', 
             fontsize=14, fontweight='bold')

plt.tight_layout()
reg_coef_path = os.path.join(OUTPUT_DIR, 'regression_coefficients.png')
plt.savefig(reg_coef_path, bbox_inches='tight', facecolor='white')
plt.close()
print(f"[OK] Coefficients de r√©gression sauvegard√©s: {reg_coef_path}")

# =============================================================================
# G√âN√âRATION DES MODEL CARDS
# =============================================================================

print("\n[INFO] G√©n√©ration des Model Cards...")

# --- MODEL CARD 1: CLASSIFICATION ---
modelcard_classification = f"""# Model Card : Pr√©diction de D√©t√©rioration

> **Document auto-g√©n√©r√©** - Derni√®re mise √† jour: {datetime.now().strftime('%d/%m/%Y √† %H:%M')}

- **Auteur**: Paul-Henri DOURNEAU & Dorian MARTY
- **Date de cr√©ation**: 09/01/2026
- **Version**: 2.0

---

## üìã R√©sum√© du Mod√®le

| Propri√©t√© | Valeur |
|-----------|--------|
| **Type** | Classification Binaire |
| **Algorithme** | R√©gression Logistique |
| **Objectif** | Alerter le personnel soignant en cas de risque de d√©t√©rioration |
| **Cible** | `deterioration_event` (0 = Stable, 1 = D√©t√©rioration) |

### Cas d'Usage M√©dical

Ce mod√®le a pour but d'**alerter le personnel soignant** en cas de risque imminent
de d√©t√©rioration de l'√©tat du patient. Une d√©t√©rioration peut inclure :
- Choc septique
- Arr√™t cardiaque
- Insuffisance respiratoire aigu√´

> ‚ö†Ô∏è **ATTENTION** : Ce mod√®le est un outil d'aide √† la d√©cision. 
> Il ne remplace pas le jugement clinique du m√©decin.

---

## üìä Donn√©es d'Entra√Ænement

| M√©trique | Valeur |
|----------|--------|
| **Dataset source** | Hospital Deterioration (Version Nettoy√©e) |
| **Taille totale** | {len(X_cls):,} observations |
| **Split train/test** | 80% / 20% |
| **Taille entra√Ænement** | {len(X_train_cls):,} observations |
| **Taille test** | {len(X_test_cls):,} observations |

### Features Utilis√©es ({len(feature_cols)} variables)

Variables physiologiques et biologiques, **excluant** :
- `patient_id` (identifiant)
- Variables cibles (√©viter fuite de donn√©es)

Lien vers le d√©tail des features : [Data_Card.md](./Data_Card.md)

---

## ‚öôÔ∏è Hyperparam√®tres

| Param√®tre | Valeur | Justification |
|-----------|--------|---------------|
| `max_iter` | 1000 | Assurer la convergence |
| `solver` | lbfgs | Par d√©faut, performant |
| `C` | 1.0 | R√©gularisation standard |
| `class_weight` | balanced | Compenser le d√©s√©quilibre de classes |
| `random_state` | 42 | Reproductibilit√© |

---

## üìà Performance et Analyse

### M√©triques Globales

| M√©trique | Valeur |
|----------|--------|
| **Accuracy** | {cls_report_dict['accuracy']:.1%} |
| **AUC-ROC** | {roc_auc:.3f} |

### Rapport de Classification

```
{cls_report}
```

### Matrice de Confusion

![Matrice de Confusion](./confusion_matrix.png)

**Interpr√©tation** :
- **TN (Vrais N√©gatifs)** : {tn:,} patients stables correctement identifi√©s
- **TP (Vrais Positifs)** : {tp:,} d√©t√©riorations correctement d√©tect√©es
- **FP (Faux Positifs)** : {fp:,} fausses alertes
- **FN (Faux N√©gatifs)** : {fn:,} d√©t√©riorations manqu√©es ‚ö†Ô∏è

> üî¥ **Point Critique** : En milieu m√©dical, les **Faux N√©gatifs** sont plus graves que les Faux Positifs.
> Un FN signifie qu'on rate une urgence potentielle.

### Courbe ROC

![Courbe ROC](./roc_curve.png)

Un AUC de **{roc_auc:.3f}** indique une capacit√© discriminante {"excellente" if roc_auc > 0.9 else "bonne" if roc_auc > 0.8 else "mod√©r√©e"}.

---

## üîç Importance des Variables

![Feature Importance](./feature_importance.png)

### Top 5 Variables Pr√©dictives

| Rang | Variable | Importance |
|------|----------|------------|
"""

# Ajouter le top 5
for i, (_, row) in enumerate(feature_importance.tail(5).iloc[::-1].iterrows(), 1):
    modelcard_classification += f"| {i} | `{row['feature']}` | {row['importance']:.3f} |\n"

modelcard_classification += f"""
---

## üí° Recommandations

### Pour am√©liorer le mod√®le

1. **Augmenter le rappel** : Ajuster le seuil de d√©cision (actuellement 0.5) vers 0.3-0.4
   pour r√©duire les Faux N√©gatifs au prix de plus de Faux Positifs
2. **Tester des mod√®les non-lin√©aires** : Random Forest, XGBoost
3. **Feature engineering** : Cr√©er des variables temporelles (tendances)

### Limites connues

- Entra√Æn√© sur un seul √©tablissement hospitalier
- Ne prend pas en compte l'historique du patient au-del√† des mesures horaires
- Performance d√©pendante de la qualit√© des donn√©es entrantes

---

## üìÅ Fichiers Associ√©s

- **Mod√®le s√©rialis√©** : [model_classification.joblib](./model_classification.joblib)
- **Data Card** : [Data_Card.md](./Data_Card.md)
- **Log transformations** : [transformation_log.md](./transformation_log.md)
- **Script de g√©n√©ration** : [modelcard.py](./modelcard.py)
"""

mc_cls_path = os.path.join(OUTPUT_DIR, 'Model_Card_Classification.md')
with open(mc_cls_path, 'w', encoding='utf-8') as f:
    f.write(modelcard_classification)
print(f"[OK] Model Card Classification sauvegard√©e: {mc_cls_path}")

# --- MODEL CARD 2: R√âGRESSION ---
modelcard_regression = f"""# Model Card : Estimation Dur√©e de S√©jour

> **Document auto-g√©n√©r√©** - Derni√®re mise √† jour: {datetime.now().strftime('%d/%m/%Y √† %H:%M')}

- **Auteur**: Paul-Henri DOURNEAU & Dorian MARTY
- **Date de cr√©ation**: 09/01/2026
- **Version**: 2.0

---

## üìã R√©sum√© du Mod√®le

| Propri√©t√© | Valeur |
|-----------|--------|
| **Type** | R√©gression |
| **Algorithme** | R√©gression Lin√©aire Multiple |
| **Objectif** | Estimer la dur√©e totale d'hospitalisation |
| **Cible** | `los_hours` (heures) |

### Cas d'Usage Hospitalier

Ce mod√®le permet d'**anticiper la gestion des lits** en pr√©disant la dur√©e totale
d'hospitalisation d'un patient en fonction de son √©tat clinique actuel.

**Applications** :
- Planification des sorties
- Optimisation de l'occupation des lits
- Estimation des ressources n√©cessaires

---

## üìä Donn√©es d'Entra√Ænement

| M√©trique | Valeur |
|----------|--------|
| **Dataset source** | Hospital Deterioration (Version Nettoy√©e) |
| **Taille totale** | {len(X_reg):,} observations |
| **Split train/test** | 80% / 20% |
| **Dur√©e moyenne (test)** | {y_test_reg.mean():.1f} heures |
| **√âcart-type dur√©e (test)** | {y_test_reg.std():.1f} heures |

Lien vers le d√©tail des features : [Data_Card.md](./Data_Card.md)

---

## ‚öôÔ∏è Param√®tres du Mod√®le

| Param√®tre | Valeur |
|-----------|--------|
| **Algorithme** | LinearRegression (sklearn) |
| **R√©gularisation** | Aucune |
| **Intercept** | {reg.intercept_:.4f} |

---

## üìà Performance et Analyse

### M√©triques de R√©gression

| M√©trique | Valeur | Interpr√©tation |
|----------|--------|----------------|
| **RMSE** | {rmse:.2f} heures | Erreur moyenne quadratique |
| **MAE** | {mae:.2f} heures | Erreur moyenne absolue |
| **R¬≤** | {r2:.4f} | Variance expliqu√©e ({r2*100:.1f}%) |

### Pr√©dictions vs Valeurs R√©elles

![Pr√©dictions vs R√©alit√©](./predictions_vs_reality.png)

**Interpr√©tation** :
- Un R¬≤ de {r2:.2f} signifie que le mod√®le explique **{r2*100:.1f}%** de la variance
- {"C'est un score modeste, typique sur des donn√©es m√©dicales complexes" if r2 < 0.5 else "C'est un r√©sultat encourageant" if r2 < 0.7 else "C'est un excellent r√©sultat"}
- L'erreur moyenne est de **{mae:.1f} heures** (environ {mae/24:.1f} jours)

### Analyse des R√©sidus

![Analyse des R√©sidus](./residuals_analysis.png)

**Observations** :
- Distribution des r√©sidus {"centr√©e autour de z√©ro ‚úì" if abs(residuals.mean()) < 1 else "l√©g√®rement biais√©e"}
- {"Pas d'h√©t√©rosc√©dasticit√© visible" if residuals.std() < 20 else "Variance augmente avec les valeurs pr√©dites"}

---

## üîç Coefficients du Mod√®le

![Coefficients de R√©gression](./regression_coefficients.png)

### Interpr√©tation des Coefficients

- **Coefficient positif** (vert) : Augmente la dur√©e de s√©jour pr√©dite
- **Coefficient n√©gatif** (rouge) : Diminue la dur√©e de s√©jour pr√©dite

### Top 5 Variables Influentes

| Rang | Variable | Coefficient | Effet |
|------|----------|-------------|-------|
"""

# Ajouter le top 5
top5_reg = reg_coef.iloc[reg_coef['coefficient'].abs().nlargest(5).index]
for i, (_, row) in enumerate(top5_reg.iterrows(), 1):
    effet = "‚Üë Dur√©e" if row['coefficient'] > 0 else "‚Üì Dur√©e"
    modelcard_regression += f"| {i} | `{row['feature']}` | {row['coefficient']:.3f} | {effet} |\n"

modelcard_regression += f"""
---

## üí° Recommandations

### Pour am√©liorer le mod√®le

1. **Mod√®les non-lin√©aires** : Random Forest ou XGBoost captureront mieux les interactions
2. **Feature engineering** : Inclure des variables temporelles (heure du jour, jour de la semaine)
3. **R√©gularisation** : Tester Ridge ou Lasso pour r√©duire l'overfitting

### Limites connues

- Mod√®le lin√©aire : ne capture pas les relations complexes
- Pr√©dictions peuvent √™tre n√©gatives (non born√©es)
- Performance variable selon le type d'admission

---

## üìÅ Fichiers Associ√©s

- **Mod√®le s√©rialis√©** : [model_regression.joblib](./model_regression.joblib)
- **Data Card** : [Data_Card.md](./Data_Card.md)
- **Log transformations** : [transformation_log.md](./transformation_log.md)
- **Script de g√©n√©ration** : [modelcard.py](./modelcard.py)
"""

mc_reg_path = os.path.join(OUTPUT_DIR, 'Model_Card_Regression.md')
with open(mc_reg_path, 'w', encoding='utf-8') as f:
    f.write(modelcard_regression)
print(f"[OK] Model Card R√©gression sauvegard√©e: {mc_reg_path}")

# Fichier combin√© pour compatibilit√©
combined_path = os.path.join(OUTPUT_DIR, 'Model_Cards.md')
with open(combined_path, 'w', encoding='utf-8') as f:
    f.write(f"# Model Cards - Vue Combin√©e\n\n")
    f.write(f"Ce fichier combine les deux Model Cards pour r√©f√©rence.\n")
    f.write(f"Pour les versions d√©taill√©es, voir:\n")
    f.write(f"- [Model_Card_Classification.md](./Model_Card_Classification.md)\n")
    f.write(f"- [Model_Card_Regression.md](./Model_Card_Regression.md)\n\n")
    f.write("---\n\n")
    f.write(modelcard_classification)
    f.write("\n\n---\n\n")
    f.write(modelcard_regression)

print("\n" + "="*60)
print("G√âN√âRATION DES MODEL CARDS TERMIN√âE")
print("="*60)
print(f"Fichiers g√©n√©r√©s:")
print(f"  - {mc_cls_path}")
print(f"  - {mc_reg_path}")
print(f"  - {combined_path}")
print(f"  - {cm_path}")
print(f"  - {roc_path}")
print(f"  - {fi_path}")
print(f"  - {pred_vs_real_path}")
print(f"  - {residuals_path}")
print(f"  - {reg_coef_path}")
print(f"  - {model_cls_path}")
print(f"  - {model_reg_path}")
print(f"  - {log_path}")